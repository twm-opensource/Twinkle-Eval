![Twinkle Eval](assets/logo.png)

# ğŸŒŸ Twinkle Evalï¼šé«˜æ•ˆä¸”æº–ç¢ºçš„ AI è©•æ¸¬å·¥å…·

[![Python](https://img.shields.io/badge/python-â‰¥3.10-blue.svg?logo=python)](https://www.python.org)
![Project Status](https://img.shields.io/badge/status-active-brightgreen)
![Platform](https://img.shields.io/badge/platform-Windows%20|%20Linux-blue)

![GitHub license](https://img.shields.io/github/license/ai-twinkle/Eval)
![GitHub issues](https://img.shields.io/github/issues/ai-twinkle/Eval)
![GitHub stars](https://img.shields.io/github/stars/ai-twinkle/Eval?style=social)
![GitHub forks](https://img.shields.io/github/forks/ai-twinkle/Eval?style=social)
[![GitHub pull request](https://img.shields.io/badge/PRs-welcome-blue)](https://github.com/ai-twinkle/Eval/pulls)

![GitHub last commit](https://img.shields.io/github/last-commit/ai-twinkle/Eval)
![GitHub repo size](https://img.shields.io/github/repo-size/ai-twinkle/Eval)
![GitHub top language](https://img.shields.io/github/languages/top/ai-twinkle/Eval)
![GitHub languages](https://img.shields.io/github/languages/count/ai-twinkle/Eval)

[![Discord](https://img.shields.io/discord/1310544431983759450?label=Twinkle%20AI&logo=discord&style=for-the-badge)](https://discord.gg/Cx737yw4ed)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Visit%20Huggingface-twinkle--ai-blue?style=for-the-badge)](https://huggingface.co/twinkle-ai)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Visit%20My%20Profile-blue?logo=linkedin&style=flat)](https://linkedin.com/company/twinkle-ai)

[![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-orange?logo=google-colab&style=for-the-badge)](https://colab.research.google.com/github/LiuYuWei/llm-colab-application/blob/main/Simon_LLM_Application_Twinkle_Eval_Tool_Google_Gemini_Model_Evaluation.ipynb)

æœ¬å°ˆæ¡ˆç‚º LLMï¼ˆLarge Language Modelï¼‰è©•æ¸¬æ¡†æ¶ï¼Œæ¡ç”¨ä¸¦è¡Œä¸”éš¨æ©ŸåŒ–æ¸¬è©¦æ–¹æ³•ï¼Œæä¾›å®¢è§€çš„æ¨¡å‹æ€§èƒ½åˆ†æèˆ‡ç©©å®šæ€§è©•ä¼°ï¼Œä¸¦æ”¯æ´å¤šç¨®å¸¸è¦‹è©•æ¸¬æ•¸æ“šé›†ã€‚
> ğŸ“– **[Twinkle Eval å¯å°è©±å¼ç¶­åŸºç™¾ç§‘é é¢ï¼ˆç”± DeepWiki ç”Ÿæˆï¼‰](https://deepwiki.tw/ai-twinkle/Eval)**  
> å‚™è¨»ï¼šå…§å®¹ç”±äººå·¥æ™ºæ…§ç”Ÿæˆï¼Œæº–ç¢ºæ€§ç„¡æ³•ä¿è­‰ï¼Œåƒ…ä¾›åƒè€ƒã€‚

## ç›®éŒ„

- [åŠŸèƒ½ç‰¹è‰²](#åŠŸèƒ½ç‰¹è‰²)
- [æ€§èƒ½æŒ‡æ¨™](#æ€§èƒ½æŒ‡æ¨™)
- [æŠ€è¡“ç‰¹é»](#æŠ€è¡“ç‰¹é»)
  - [è©•æ¸¬æ–¹æ³•](#è©•æ¸¬æ–¹æ³•)
  - [æ”¯æ´æ ¼å¼åŠå¸¸è¦‹æ•¸æ“šé›†](#æ”¯æ´æ ¼å¼åŠå¸¸è¦‹æ•¸æ“šé›†)
  - [API æ•ˆèƒ½è¨­å®š](#api-æ•ˆèƒ½è¨­å®š)
- [å®‰è£è¨­å®š](#å®‰è£è¨­å®š)
- [ä½¿ç”¨æ–¹å¼](#ä½¿ç”¨æ–¹å¼)
- [è¨­å®šæª”èªªæ˜](#è¨­å®šæª”èªªæ˜)
  - [LLM API è¨­å®š](#llm-api-è¨­å®š)
  - [æ¨¡å‹è¨­å®š](#æ¨¡å‹è¨­å®š)
  - [è©•æ¸¬è¨­å®š](#è©•æ¸¬è¨­å®š)
  - [æ—¥èªŒè¨­å®š](#æ—¥èªŒè¨­å®š)
- [è¼¸å‡ºçµæœ](#è¼¸å‡ºçµæœ)
- [æ¨¡å‹å¯¦æ¸¬çµæœ](#æ¨¡å‹å¯¦æ¸¬çµæœ)
- [è²¢ç»è€…](#è²¢ç»è€…)
- [æˆæ¬Šæ¢æ¬¾](#æˆæ¬Šæ¢æ¬¾)
- [å¼•ç”¨](#å¼•ç”¨)
- [è‡´è¬](#è‡´è¬)

## åŠŸèƒ½ç‰¹è‰²

- **è‡ªå‹•åŒ–è©•æ¸¬å¤šå€‹æª”æ¡ˆ**ï¼šå¯æ‰¹æ¬¡è™•ç†ä¸¦çµ±ä¸€ç”Ÿæˆè©•æ¸¬çµæœã€‚
- **å¯è‡ªè¨‚è©•æ¸¬åƒæ•¸èˆ‡ç”Ÿæˆæ§åˆ¶**ï¼šå¯è¨­å®šæº«åº¦ã€top_p ç­‰ç”Ÿæˆåƒæ•¸ã€‚
- **é¸é …éš¨æ©Ÿæ’åˆ—åŠŸèƒ½**ï¼šé¿å…æ¨¡å‹å› é¸é …é †åºç”¢ç”Ÿåå¥½ã€‚
- **Pattern æˆ– Box é›™æ¨¡å¼è©•æ¸¬**ï¼šæ”¯æ´æ–‡å­—åŒ¹é…æˆ–æ¡†é¸è©•åˆ†é‚è¼¯ã€‚
- **å¤šæ¬¡æ¸¬è©¦å¹³å‡åˆ†æ**ï¼šè¨­å®šæ¸¬è©¦å›åˆæ•¸ä»¥è§€å¯Ÿæ¨¡å‹è¡¨ç¾ç©©å®šæ€§ã€‚
- **è¨ˆç®—å¹³å‡æ­£ç¢ºç‡èˆ‡ç©©å®šæ€§æŒ‡æ¨™**ï¼šé‡åŒ–æ¨¡å‹ç­”é¡Œæº–ç¢ºåº¦èˆ‡æ³¢å‹•ç¨‹åº¦ã€‚
- **ç´€éŒ„ LLM æ¨è«–èˆ‡çµ±è¨ˆçµæœ**ï¼šç”¨æ–¼å¾ŒçºŒåˆ†ææ¨¡å‹åœ¨å„é¡é¡Œå‹çš„è¡¨ç¾ã€‚
- **æ”¯æ´ OpenAI API æ ¼å¼**ï¼šç›¸å®¹æ–¼å¸¸è¦‹çš„ GPT API è¼¸å…¥èˆ‡è¼¸å‡ºæ ¼å¼ã€‚
- **å®‰å…¨åœ°è™•ç† API é‡‘é‘°**ï¼šé¿å…é‡‘é‘°æš´éœ²æ–¼ç¨‹å¼ç¢¼æˆ–æ—¥èªŒä¸­ã€‚
- **API è«‹æ±‚é™æµæ§åˆ¶èˆ‡è‡ªå‹•é‡è©¦æ©Ÿåˆ¶**ï¼šæ¸›å°‘éŒ¯èª¤ç™¼ç”Ÿä¸¦æé«˜ API è«‹æ±‚æˆåŠŸç‡ã€‚

## æ€§èƒ½æŒ‡æ¨™

ä¸‹åœ–å±•ç¤ºäº†åœ¨ [ikala/tmmluplus](https://huggingface.co/datasets/ikala/tmmluplus) - **basic_medical_science**ï¼ˆå…± 954 é¡Œï¼‰å­ä»»å‹™ä¸Šï¼ŒTwinkle Eval èˆ‡ç¾æœ‰å·¥å…· [iKala/ievals](https://github.com/iKala/ievals) åœ¨ä¸‰ç¨®æ¨¡å‹ä¸‹çš„æ¨è«–æ™‚é–“æ¯”è¼ƒï¼š

![TMMLU è©•æ¸¬æ™‚é–“çµ±è¨ˆ](assets/tmmlu_eval_time_rounded_seconds.png)

- [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct) (éæ¨ç†ä»»å‹™)ï¼šTwinkle Eval å¿«äº† **9.4 å€**ã€‚
- [deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) (æ¨ç†ä»»å‹™)ï¼šTwinkle Eval å¿«äº† **16.9 å€**ã€‚
- [mistralai/Mistral-Small-24B-Instruct-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501) (éæ¨ç†ä»»å‹™)ï¼šTwinkle Eval å¿«äº† **14.5 å€**ã€‚

é€™é …å¯¦é©—çµæœé¡¯ç¤ºï¼Œ**Twinkle Eval åœ¨ä¸åŒæ¨¡å‹å¤§å°èˆ‡ä»»å‹™é¡å‹ä¸‹çš†èƒ½é¡¯è‘—æå‡æ•ˆèƒ½ï¼Œæœ€é«˜é”è¿‘ 17 å€é€Ÿåº¦å„ªå‹¢**ï¼ŒåŒæ™‚ä¿æŒæº–ç¢ºç‡ä¸€è‡´ã€‚é€™å°æ–¼éœ€è¦å¤§é‡è©•æ¸¬çš„ LLM é–‹ç™¼å·¥ä½œæµç¨‹ï¼Œèƒ½å¤§å¹…ç¸®çŸ­é€±æœŸã€ç¯€çœæˆæœ¬ã€‚

## æŠ€è¡“ç‰¹é»

### è©•æ¸¬æ–¹æ³•

- **éš¨æ©ŸåŒ–æ¸¬è©¦**ï¼šåƒè€ƒ [Changing Answer Order Can Decrease MMLU Accuracy](https://arxiv.org/html/2406.19470v1)ï¼Œå¯¦ä½œ**é¸é …éš¨æ©Ÿæ’åˆ—åŠŸèƒ½**ï¼Œæ›´èƒ½å®¢è§€çš„è©•ä¼°æ¨¡å‹èƒ½åŠ›ã€‚
- **ç©©å®šæ€§åˆ†æ**ï¼šæ”¯æ´å¤šæ¬¡æ¸¬è©¦ä¸¦é€²è¡Œçµ±è¨ˆåˆ†æã€‚
- **æ ¼å¼æ§åˆ¶**ï¼šæŒ‡å®š `\box{é¸é …}` æˆ– `\boxed{é¸é …}` ç­‰æ¡†é¸æ ¼å¼ï¼Œåš´æ ¼ç®¡ç†è¼¸å‡ºå‘ˆç¾æ¨£å¼ã€‚
- **éŒ¯èª¤è™•ç†**ï¼šè‡ªå‹•é‡è©¦èˆ‡è¶…æ™‚æ§åˆ¶æ©Ÿåˆ¶ã€‚

### æ”¯æ´æ ¼å¼åŠå¸¸è¦‹æ•¸æ“šé›†

ä»»ä½•ç¬¦åˆä»¥ä¸‹æ ¼å¼çš„ `.csv`ã€`.json`ã€`.jsonl` æˆ– `.parquet` æª”æ¡ˆï¼Œå…§å®¹éœ€åŒ…å«ä¸‹åˆ—æ¬„ä½æ ¼å¼ï¼ˆä¸é™æ–¼ TMMLU+ï¼‰ï¼š

```csv
  question,A,B,C,D,answer
```

ä»¥ä¸‹åˆ—å‡ºå·²çŸ¥è©•æ¸¬é›†ï¼š

- [TMMLU+](https://huggingface.co/datasets/ikala/tmmluplus)
- [MMLU](https://github.com/hendrycks/test)
- [tw-legal-benchmark-v1](https://huggingface.co/datasets/lianghsun/tw-legal-benchmark-v1)
- [Formosa-bench](https://huggingface.co/datasets/lianghsun/Formosa-bench)

### API æ•ˆèƒ½è¨­å®š

- è¨­å®šè«‹æ±‚é™æµï¼šç„¡é™åˆ¶æˆ–æŒ‡å®š QPSï¼ˆQueries Per Secondï¼‰æ•¸å€¼ã€‚
- è¶…æ™‚è¨­å®šã€‚
- å¯é¸æ˜¯å¦é€²è¡Œ SSL é©—è­‰ã€‚
- éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶ã€‚

## å®‰è£è¨­å®š

1. è¤‡è£½å°ˆæ¡ˆè‡³æœ¬æ©Ÿ
   ```bash
   git clone https://github.com/ai-twinkle/Eval.git
   ```
2. å®‰è£ç›¸ä¾å¥—ä»¶
   ```bash
   pip install -r requirements.txt
   ```

## ä½¿ç”¨æ–¹å¼

1. è¤‡è£½ `config.template.yaml` ç‚º `config.yaml` ä¸¦ä¾æ“šéœ€æ±‚æ›´æ–°è¨­å®šã€‚
2. å°‡è©•æ¸¬æ•¸æ“šé›†æª”æ¡ˆæ”¾å…¥è³‡æ–™é›†ç›®éŒ„ `datasets`ã€‚
3. åŸ·è¡Œè©•æ¸¬ï¼š
   ```bash
   python main.py
   ```

è©•æ¸¬çµæœæœƒå„²å­˜åœ¨ `results` ç›®éŒ„ä¸­ï¼Œæª”ååŒ…å«æ™‚é–“æˆ³è¨˜ã€‚

## è¨­å®šæª”èªªæ˜

è¨­å®šæª”ä½¿ç”¨ YAML æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦å€æ®µï¼š

### LLM API è¨­å®š

```yaml
llm_api:
  base_url: "http://your-openai-compatible-server/v1" # API ä¼ºæœå™¨ç¶²å€
  api_key: "your-api-key" # API é‡‘é‘°
  disable_ssl_verify: false # æ˜¯å¦åœç”¨ SSL é©—è­‰
  api_rate_limit: 2 # æ¯ç§’è«‹æ±‚é™åˆ¶ï¼ˆ-1 ç‚ºä¸é™åˆ¶ï¼‰
  max_retries: 5 # API å‘¼å«å¤±æ•—æ™‚çš„é‡è©¦æ¬¡æ•¸
  timeout: 600 # API å‘¼å«çš„è¶…æ™‚æ™‚é–“ (ç§’)
```

### æ¨¡å‹è¨­å®š

```yaml
model:
  name: "model-name" # æ¨¡å‹åç¨±
  temperature: 0.0 # æº«åº¦åƒæ•¸
  top_p: 0.9 # Top-p æ©Ÿç‡é–¾å€¼
  max_tokens: 4096 # æœ€å¤§è¼¸å‡º token æ•¸
  frequency_penalty: 0.0 # é »ç‡æ‡²ç½°
  presence_penalty: 0.0 # å­˜åœ¨æ‡²ç½°
```

### è©•æ¸¬è¨­å®š

```yaml
evaluation:
  dataset_paths: # è³‡æ–™é›†è·¯å¾‘
    - "datasets/dataset1/"
    - "datasets/dataset2/"
  evaluation_method: "box" # è©•æ¸¬æ–¹æ³•ï¼ˆæ”¯æ´ "pattern" æˆ– "box"ï¼‰
  system_prompt: | # ç³»çµ±æç¤ºè©ï¼Œåƒ…æ–¼ box è©•æ¸¬æ–¹æ³•ä¸­ä½¿ç”¨
    ä½¿ç”¨è€…å°‡æä¾›ä¸€å€‹é¡Œç›®ï¼Œä¸¦é™„ä¸Šé¸é … Aã€Bã€Cã€D
    è«‹ä»”ç´°é–±è®€é¡Œç›®è¦æ±‚ï¼Œæ ¹æ“šé¡Œæ„é¸å‡ºæœ€ç¬¦åˆçš„é¸é …ï¼Œä¸¦å°‡é¸é …ä»¥ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š
    \box{é¸é …}
    è«‹ç¢ºä¿åƒ…å°‡é¸é …åŒ…å«åœ¨ { } ä¸­ï¼Œå¦å‰‡å°‡ä¸è¨ˆç®—ç‚ºæœ‰æ•ˆç­”æ¡ˆã€‚
    å‹™å¿…ç²¾ç¢ºéµå¾ªè¼¸å‡ºæ ¼å¼ï¼Œé¿å…ä»»ä½•å¤šé¤˜å…§å®¹æˆ–éŒ¯èª¤æ ¼å¼ã€‚
  repeat_runs: 5 # å–®ä¸€ datasets é‡è¤‡åŸ·è¡Œæ¬¡æ•¸
  shuffle_options: true # æ˜¯å¦å°é¸é …é€²è¡Œéš¨æ©Ÿæ’åº
```

### æ—¥èªŒè¨­å®š

```yaml
logging:
  level: "INFO" # æ—¥èªŒç­‰ç´šï¼ˆå¯é¸ DEBUG, INFO, WARNING, ERRORï¼‰
```

## è¼¸å‡ºçµæœ

æœ¬å°ˆæ¡ˆè¼¸å‡ºå…©ä»½çµæœï¼Œåˆ†åˆ¥ç‚º `results_{timestamp}.json` èˆ‡ `eval_results_{timestamp}.json`ã€‚

### `results_{timestamp}.json`

é€™å€‹æª”æ¡ˆä¸»è¦ç”¨ä¾†**çµ±æ•´æ•´ä»½è©•æ¸¬çš„æ‘˜è¦è³‡è¨Š**ï¼Œé©åˆï¼š

- å¿«é€ŸæŸ¥çœ‹æ¨¡å‹åœ¨å¤šä»½è³‡æ–™é›†ä¸Šçš„è¡¨ç¾
- å°æ¯”ä¸åŒæ¨¡å‹ã€è¨­å®šçš„å¹³å‡æº–ç¢ºç‡
- å°ç…§ä½¿ç”¨çš„æ¨¡å‹åƒæ•¸ã€API è¨­å®š
- å¯æ­é… timestamp ä½œç‚ºè©•æ¸¬ç‰ˆæœ¬æ§åˆ¶ç´€éŒ„ä¾æ“š

```json
{
  "timestamp": "20250314_1158", // è©•æ¸¬åŸ·è¡Œçš„æ™‚é–“æˆ³è¨˜
  "results": [
    // å„å€‹æ¸¬è©¦æª”æ¡ˆçš„è©•æ¸¬çµæœ
    {
      "file": "datasets/test/basic_medical_science_train.csv", // æ¸¬è©¦æª”æ¡ˆè·¯å¾‘
      "accuracy": 0.4 // æ¨¡å‹åœ¨è©²æª”æ¡ˆä¸Šçš„æ­£ç¢ºç‡
    },
    {
      "file": "datasets/test/culinary_skills_dev.csv",
      "accuracy": 0.4
    }
  ],
  "average_accuracy": 0.4, // æ‰€æœ‰è³‡æ–™é›†çš„å¹³å‡æ­£ç¢ºç‡
  "config": {
    "llm_api": {
      "base_url": "http://localhost:8002/v1/", // å‘¼å«æ¨¡å‹çš„ API ç«¯é»
      "api_key": "EMPTY" // API é‡‘é‘°ï¼ˆæ­¤è™•ç‚ºç©ºï¼‰
    },
    "model": {
      "name": "checkpoint-108", // ä½¿ç”¨çš„æ¨¡å‹åç¨±
      "temperature": 0, // æº«åº¦åƒæ•¸ï¼ˆå½±éŸ¿éš¨æ©Ÿæ€§ï¼‰
      "top_p": 0.9, // Top-p æ¡æ¨£åƒæ•¸
      "max_tokens": 4096, // æœ€å¤§ç”Ÿæˆé•·åº¦
      "frequency_penalty": 0,
      "presence_penalty": 0
    },
    "evaluation": {
      "dataset_path": "datasets/test/", // è©•æ¸¬è³‡æ–™é›†ç›®éŒ„
      "api_concurrency": 40, // ä¸¦è¡Œè«‹æ±‚æ•¸ï¼ˆå½±éŸ¿æ¨è«–é€Ÿåº¦ï¼‰
      "evaluation_method": "box", // è©•æ¸¬æ–¹å¼ç‚º box æ¨¡å¼
      "system_prompt": "ä»¥ä¸‹ä½¿ç”¨è€…æœƒçµ¦ä½ é¸æ“‡ A, B, C, Dï¼Œè«‹ä½ è¦é¸å‡ºç¬¦åˆé¡Œç›®è¦æ±‚çš„ç­”æ¡ˆï¼Œä¸¦ä¸”å°‡ç­”æ¡ˆæ”¾è‡³ \\box{} è£¡é¢..." // æŒ‡å®šæ¨¡å‹å›è¦†æ ¼å¼çš„æç¤ºèª
    }
  },
  "logging": {
    "level": "INFO" // æ—¥èªŒç­‰ç´š
  }
}
```

### `eval_results_{timestamp}.json`

é€™å€‹æª”æ¡ˆç”¨ä¾†**è¨˜éŒ„å–®ä¸€æ¸¬è©¦æª”ä¸­æ¯ä¸€é¡Œçš„ç­”é¡Œç‹€æ³**ï¼Œé©åˆï¼š

- åˆ†æéŒ¯é¡Œã€äº†è§£æ¨¡å‹å‡ºéŒ¯çš„å‚¾å‘
- æ­é…è³‡æ–™è¦–è¦ºåŒ–ï¼ˆå¦‚ confusion matrixã€éŒ¯èª¤ç‡ç†±åœ–ï¼‰

```json
{
  "timestamp": "20250314_1158",  // è©•æ¸¬åŸ·è¡Œçš„æ™‚é–“æˆ³è¨˜
  "file": "datasets/test/basic_medical_science_train.csv",  // æ¸¬è©¦æª”æ¡ˆè·¯å¾‘
  "accuracy": 0.4,  // æ¨¡å‹åœ¨è©²æª”æ¡ˆä¸Šçš„æ•´é«”æ­£ç¢ºç‡

  "details": [  // æ¯é¡Œçš„è©•æ¸¬è©³æƒ…
    {
      "question_id": 0,  // é¡Œç›®ç·¨è™Ÿ
      "question": "ä¸‹åˆ—ä½•è€…åƒ…ä½æ–¼è…è‡Ÿçš®è³ªï¼ˆcortexï¼‰ï¼ŸA: ä¹³é ­ç®¡ ...",  // é¡Œç›®å…§å®¹èˆ‡é¸é …
      "correct_answer": "C",  // æ­£ç¢ºç­”æ¡ˆ
      "predicted_answer": "C",  // æ¨¡å‹é æ¸¬ç­”æ¡ˆ
      "is_correct": true  // é æ¸¬æ˜¯å¦æ­£ç¢º
    },
    {
      "question_id": 1,
      ...
    }
  ]
}
```

## æ¨¡å‹å¯¦æ¸¬çµæœ

> [!NOTE]
> æœ¬è¡¨å°‡éš¨æ™‚é–“æ›´æ–°æ¨¡å‹è©•æ¸¬åˆ†æ•¸

| æ¨¡å‹                                                                                                                          | è©•æ¸¬æ¨¡å¼ | TMMLU+(%)       | tw-legal(%)     | MMLU(%)         | æ¸¬è©¦æ¬¡æ•¸ | é¸é …æ’åº |
| ----------------------------------------------------------------------------------------------------------------------------- | -------- | --------------- | --------------- | --------------- | -------- | -------- |
| [meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8) | box      | 78.27 (Â±0.0130) | 61.40 (Â±0.0081) | 87.26 (Â±0.0085) | 3        | éš¨æ©Ÿ     |
| [meta-llama/Llama-4-Scout-17B-16E-Instruct](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct)                 | box      | 67.71 (Â±0.0147) | 47.21 (Â±0.0045) | 83.31 (Â±0.0097) | 3        | éš¨æ©Ÿ     |
| [mistralai/Mistral-Small-24B-Instruct-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501)                 | box      | 56.15 (Â±0.0172) | 37.48 (Â±0.0098) | 74.61 (Â±0.0154) | 3        | éš¨æ©Ÿ     |
| [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)                                   | box      | 15.49 (Â±0.0104) | 25.68 (Â±0.0200) | 6.90 (Â±0.0096)  | 3        | éš¨æ©Ÿ     |
| [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)                                   | pattern  | 35.85 (Â±0.0174) | 32.22 (Â±0.0023) | 59.33 (Â±0.0168) | 3        | éš¨æ©Ÿ     |
| [MediaTek-Research/Llama-Breeze2-3B-Instruct](https://huggingface.co/MediaTek-Research/Llama-Breeze2-3B-Instruct)             | pattern  | 40.32 (Â±0.0181) | 38.92 (Â±0.0193) | 55.37 (Â±0.0180) | 3        | éš¨æ©Ÿ     |
| [twinkle-ai/Llama-3.2-3B-F1-Instruct](https://huggingface.co/twinkle-ai/Llama-3.2-3B-F1-Instruct)                             | box      | 46.16 (Â±0.0198) | 34.92 (Â±0.0243) | 51.22 (Â±0.0206) | 3        | éš¨æ©Ÿ     |

## è²¢ç»è€…

[![Teds Lin](https://img.shields.io/badge/GitHub-Teds%20Lin-blue?logo=github)](https://github.com/teds-lin)
[![Liang Hsun Huang](https://img.shields.io/badge/GitHub-Huang%20Liang%20Hsun-blue?logo=github)](https://github.com/lianghsun)
[![Min Yi Chen](https://img.shields.io/badge/GitHub-Min%20Yi%20Chen-blue?logo=github)](https://github.com/cyc00518)
[![Dave Sung](https://img.shields.io/badge/GitHub-Dave%20Sung-blue?logo=github)](https://github.com/k1dav)

æœ¬å°ˆæ¡ˆç”± [Twinkle AI](https://github.com/ai-twinkle) èˆ‡ [APMIC](https://www.apmic.ai/) åˆä½œé–‹ç™¼ã€‚

## æˆæ¬Šæ¢æ¬¾

æœ¬å„²å­˜åº«çš„åŸå§‹ç¢¼ä¾ç…§ [MIT](https://github.com/ai-twinkle/Eval?tab=MIT-1-ov-file#readme) æˆæ¬Šæ¢æ¬¾é–‹æºã€‚

## å¼•ç”¨

å¦‚æœæ‚¨è¦ºå¾—æ­¤è©•æ¸¬å·¥å…·æœ‰å¹«åŠ©åˆ°ï¼Œè«‹å†ä¸åå¼•ç”¨å¦‚ä¸‹ï¼š

```bibtex
@misc{twinkle_eval,
  author       = {Teds Lin, Liang Hsun Huang, Min Yi Chen and Dave Sung},
  title        = {Twinkle Eval: An Efficient and Accurate AI Evaluation Tool.},
  year         = {2025},
  url          = {https://github.com/ai-twinkle/Eval},
  note         = {GitHub repository}
}
```

## è‡´è¬

åœ¨æœ¬å°ˆæ¡ˆçš„é–‹ç™¼éç¨‹ä¸­ï¼Œæˆ‘å€‘åƒè€ƒäº† [iKala/ievals](https://github.com/iKala/ievals) å°ˆæ¡ˆä¸­çš„æ¨¡å¼è¨­è¨ˆç†å¿µï¼Œè©²å°ˆæ¡ˆå°æˆ‘å€‘çš„è¨­è¨ˆæ–¹å‘æä¾›äº†å¯¶è²´çš„å•Ÿç™¼ï¼Œç‰¹æ­¤è‡´ä¸Šèª æ‘¯æ„Ÿè¬ã€‚
åŒæ™‚ä¹Ÿæ„Ÿè¬ [Simon Liu](https://simonliuyuwei-4ndgcf4.gamma.site/) æä¾›çš„ Colab [ç¤ºç¯„ç¯„ä¾‹](https://colab.research.google.com/github/LiuYuWei/llm-colab-application/blob/main/Simon_LLM_Application_Twinkle_Eval_Tool_Google_Gemini_Model_Evaluation.ipynb)ï¼Œå”åŠ©æˆ‘å€‘æ›´ç›´è§€åœ°å‘ˆç¾å·¥å…·çš„ä½¿ç”¨æ–¹å¼èˆ‡å¯¦éš›æ‡‰ç”¨å ´æ™¯ã€‚
