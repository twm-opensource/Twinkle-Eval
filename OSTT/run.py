import argparse
from twinkle_eval import TwinkleEvalRunner
import json, pandas as pd, os, random, glob, yaml, tempfile, numpy as np
from collections import Counter
from datetime import datetime


# === ğŸ§© æŠ½æ¨£åŠŸèƒ½ ===
def prepare_sample_dataset(src_path, sample_path, n=50, seed=42):
    """å¾åŸå§‹è³‡æ–™é›†ä¸­æŠ½æ¨£ N é¡Œï¼Œè¼¸å‡ºåˆ°æš«å­˜è³‡æ–™å¤¾"""
    os.makedirs(sample_path, exist_ok=True)
    random.seed(seed)
    for file in glob.glob(os.path.join(src_path, "*.csv")):
        df = pd.read_csv(file)
        if len(df) > n:
            df = df.sample(n=n, random_state=seed)
        dst_file = os.path.join(sample_path, os.path.basename(file))
        df.to_csv(dst_file, index=False, encoding="utf-8-sig")
        print(f"ğŸ“ å·²æŠ½æ¨£ {len(df)} é¡Œ -> {dst_file}")
    return sample_path


# === ğŸš€ è·‘ Twinkle-Eval ===
def run_taigi_evaluation(config_path="config.yaml", sample_path=None):
    """åŸ·è¡Œå°èªè©¦é¡Œè©•æ¸¬ï¼Œå…è¨±å‹•æ…‹æŒ‡å®šæŠ½æ¨£è³‡æ–™å¤¾"""
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    if sample_path:
        config["evaluation"]["dataset_paths"] = [sample_path]
        print(f"ğŸ“‚ ä½¿ç”¨æŠ½æ¨£å¾Œè³‡æ–™é›†: {sample_path}")

    # å»ºç«‹æš«å­˜ YAML æª”çµ¦ Twinkle-Eval
    with tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".yaml", encoding="utf-8") as tmp:
        yaml.dump(config, tmp, allow_unicode=True)
        tmp_path = tmp.name

    runner = TwinkleEvalRunner(tmp_path)
    print("ğŸ”§ åˆå§‹åŒ–è©•æ¸¬ç’°å¢ƒ...")
    runner.initialize()
    print("ğŸš€ é–‹å§‹è©•æ¸¬...")
    results = runner.run_evaluation(export_formats=["json", "csv", "html"])
    print(f"\nâœ… è©•æ¸¬å®Œæˆ! ğŸ“ çµæœå·²å„²å­˜è‡³: {results}")
    return results


# === ğŸ“Š çµæœåˆ†æ ===
def analyze_results(result_file):
    """åˆ†æè©•æ¸¬çµæœï¼šè‡ªå‹•åµæ¸¬ Twinkle-Eval çµæ§‹"""
    import json

    if result_file.endswith(".json"):
        with open(result_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        print("\n" + "=" * 50)
        print("ğŸ“Š è©•æ¸¬çµæœåˆ†æ (Summary)")
        print("=" * 50)

        acc, std = 0, 0

        # âœ… æ”¯æ´å¤šç¨®ç‰ˆæœ¬çµæ§‹
        if "dataset_results" in data:
            dataset_dict = next(iter(data["dataset_results"].values()))
            acc = dataset_dict.get("average_accuracy", 0)
            std = dataset_dict.get("average_std", 0)
        elif "datasets" in data:
            first = data["datasets"][0]
            acc = first.get("avg_accuracy", 0)
            std = first.get("std_accuracy", 0)
        else:
            acc = (
                data.get("overall_accuracy")
                or data.get("average_accuracy")
                or data.get("accuracy")
                or 0
            )
            std = (
                data.get("overall_std")
                or data.get("std_accuracy")
                or 0
            )

        print(f"\nå¹³å‡æº–ç¢ºç‡: {acc:.2%}")
        print(f"æ¨™æº–å·®: {std:.2%}")
        return acc

    # === é€é¡Œ jsonl ===
    with open(result_file, "r", encoding="utf-8") as f:
        lines = [json.loads(line) for line in f]
    if not lines:
        print("âš ï¸ æª”æ¡ˆç‚ºç©ºï¼Œç„¡æ³•åˆ†æã€‚")
        return 0

    total = len(lines)
    correct = sum(1 for x in lines if x.get("is_correct"))
    acc = correct / total if total > 0 else 0

    print("\n" + "=" * 50)
    print("ğŸ“Š è©•æ¸¬çµæœåˆ†æ (é€é¡Œ)")
    print("=" * 50)
    print(f"ç¸½é¡Œæ•¸: {total}")
    print(f"ç­”å°é¡Œæ•¸: {correct}")
    print(f"ç­”éŒ¯é¡Œæ•¸: {total - correct}")
    print(f"æ¨ç®—æº–ç¢ºç‡: {acc:.2%}")
    return acc


# === ğŸ§® ä¸»æµç¨‹ ===
if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="åŸ·è¡Œ Twinkle-Eval éš¨æ©ŸæŠ½æ¨£è©•æ¸¬.")
    parser.add_argument(
        "--src_dir", 
        type=str, 
        default="dataset", # é è¨­å€¼æ”¹ç‚ºç›¸å°è·¯å¾‘ï¼Œè¼ƒé€šç”¨
        help="åŸå§‹è³‡æ–™é›† (.csv) æ‰€åœ¨çš„è·¯å¾‘ã€‚"
    )
    parser.add_argument(
        "--sample_dir", 
        type=str, 
        default="dataset_sampled", # é è¨­å€¼æ”¹ç‚ºç›¸å°è·¯å¾‘
        help="æš«å­˜æŠ½æ¨£è³‡æ–™é›†è¦è¼¸å‡ºçš„è·¯å¾‘ã€‚"
    )
    parser.add_argument(
        "--num_rounds", 
        type=int, 
        default=5, 
        help="åŸ·è¡ŒæŠ½æ¨£è©•æ¸¬çš„è¼ªæ•¸ (è¿´åœˆæ¬¡æ•¸)ã€‚"
    )
    parser.add_argument(
        "--sample_n", 
        type=int, 
        default=50, 
        help="æ¯è¼ªæŠ½æ¨£çš„é¡Œç›®æ•¸é‡ (n)ã€‚"
    )
    args = parser.parse_args()

    # ä½¿ç”¨å‚³å…¥çš„åƒæ•¸
    SRC = args.src_dir
    SAMPLE = args.sample_dir

    os.makedirs("results", exist_ok=True)
    summary_records = []

    for i in range(5):
        print(f"\n==============================")
        print(f"ğŸ” ç¬¬ {i+1} æ¬¡æŠ½æ¨£èˆ‡è©•æ¸¬")
        print(f"==============================")

        seed = random.randint(1, 9999)
        prepare_sample_dataset(SRC, SAMPLE, n=args.sample_n, seed=seed)

        # === è¨˜éŒ„èˆŠæª”ï¼Œé¿å…å¤šé‡é™„åŠ  ===
        existing_files = set(glob.glob("results/*.json*"))
        run_taigi_evaluation("config.yaml", sample_path=SAMPLE)

        # === æ‰¾å‡ºæ–°æª”ä¸¦æ”¹å ===
        new_files = set(glob.glob("results/*.json*")) - existing_files
        renamed_files = []
        for f in new_files:
            if f.endswith(".jsonl"):
                new_name = f.replace(".jsonl", f"_round{i+1}.jsonl")
            elif f.endswith(".json"):
                new_name = f.replace(".json", f"_round{i+1}.json")
            else:
                continue
            os.rename(f, new_name)
            renamed_files.append(new_name)

        # === æ‰¾å‡º summary åˆ†æ ===
        json_summaries = [f for f in renamed_files if f.endswith(".json")]
        acc = 0
        if json_summaries:
            acc = analyze_results(json_summaries[0])
        summary_records.append({"round": i + 1, "seed": seed, "accuracy": acc})

    # === ğŸ§¾ è¼¸å‡ºäº”è¼ªç¸½çµ ===
    if summary_records:
        df = pd.DataFrame(summary_records)
        mean_acc = df["accuracy"].mean()
        std_acc = df["accuracy"].std()
        df.to_csv("results/summary.csv", index=False, encoding="utf-8-sig")

        print("\n" + "=" * 50)
        print(f"ğŸ äº”è¼ªå¹³å‡æº–ç¢ºç‡: {mean_acc:.2%} (Â±{std_acc:.2%})")
        print(f"ğŸ“Š è©³ç´°çµæœå·²è¼¸å‡º: results/summary.csv")
        print("=" * 50)